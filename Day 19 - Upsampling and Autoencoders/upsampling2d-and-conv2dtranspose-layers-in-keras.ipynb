{"cells":[{"metadata":{},"cell_type":"markdown","source":"# How to use the UpSampling2D and Conv2DTranspose Layers in Keras\n(https://machinelearningmastery.com/upsampling-and-transpose-convolution-layers-for-generative-adversarial-networks/)"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport keras\nfrom keras.models import Sequential\nfrom keras.layers import UpSampling2D\nimport tensorflow as tf\nfrom tensorflow.keras.layers import Dense, Dropout, Activation, Flatten\nfrom tensorflow.keras.layers import Reshape\nfrom keras.models import Sequential\nfrom keras.layers import Conv2D, MaxPooling2D\nfrom keras.layers import Conv2DTranspose\nimport matplotlib.pyplot as plt\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":27,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### How to Use the UpSampling2D Layer"},{"metadata":{"trusted":true},"cell_type":"code","source":"...\n# define model\nmodel = Sequential()\nmodel.add(UpSampling2D())","execution_count":6,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"...\n# define input data\nX = np.asarray([[1, 2],\n\t\t\t [3, 4]])\n# show input data for context\nprint(X)","execution_count":8,"outputs":[{"output_type":"stream","text":"[[1 2]\n [3 4]]\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"...\n# reshape input data into one sample a sample with a channel\nX = X.reshape((1, 2, 2, 1))","execution_count":9,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"...\n# define model\nmodel = Sequential()\nmodel.add(UpSampling2D(input_shape=(2, 2, 1)))\n# summarize the model\nmodel.summary()","execution_count":10,"outputs":[{"output_type":"stream","text":"Model: \"sequential_1\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\nup_sampling2d_1 (UpSampling2 (None, 4, 4, 1)           0         \n=================================================================\nTotal params: 0\nTrainable params: 0\nNon-trainable params: 0\n_________________________________________________________________\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"...\n# make a prediction with the model\nyhat = model.predict(X)","execution_count":11,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"...\n# reshape output to remove channel to make printing easier\nyhat = yhat.reshape((4, 4))\n# summarize output\nprint(yhat)","execution_count":12,"outputs":[{"output_type":"stream","text":"[[1. 1. 2. 2.]\n [1. 1. 2. 2.]\n [3. 3. 4. 4.]\n [3. 3. 4. 4.]]\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"...\n# example of using different scale factors for each dimension\nmodel.add(UpSampling2D(size=(2, 3)))","execution_count":13,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"...\n# example of using bilinear interpolation when upsampling\nmodel.add(UpSampling2D(interpolation='bilinear'))","execution_count":14,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Simple Generator Model With the UpSampling2D Layer\n- GAN generator model must produce a 10×10 image and take a 100 element vector from the latent space as input.\n- a Dense fully connected layer can be used to interpret the input vector and create a sufficient number of activations (outputs) that can be reshaped into a low-resolution version of our output image, in this case, 128 versions of a 5×5 image."},{"metadata":{"trusted":true},"cell_type":"code","source":"...\n# define model\nmodel = Sequential()\n# define input shape, output enough activations for for 128 5x5 image\nmodel.add(Dense(128 * 5 * 5, input_dim=100))\n# reshape vector of activations into 128 feature maps with 5x5\nmodel.add(Reshape((5, 5, 128)))","execution_count":19,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"...\n# double input from 128 5x5 to 1 10x10 feature map\nmodel.add(UpSampling2D())","execution_count":21,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"...\n# fill in detail in the upsampled feature maps\nmodel.add(Conv2D(1, (3,3), padding='same'))","execution_count":24,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# summarize model\nmodel.summary()","execution_count":25,"outputs":[{"output_type":"stream","text":"Model: \"sequential_4\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\ndense_1 (Dense)              (None, 3200)              323200    \n_________________________________________________________________\nreshape (Reshape)            (None, 5, 5, 128)         0         \n_________________________________________________________________\nup_sampling2d_4 (UpSampling2 (None, 10, 10, 128)       0         \n_________________________________________________________________\nup_sampling2d_5 (UpSampling2 (None, 20, 20, 128)       0         \n_________________________________________________________________\nconv2d (Conv2D)              (None, 20, 20, 1)         1153      \n=================================================================\nTotal params: 324,353\nTrainable params: 324,353\nNon-trainable params: 0\n_________________________________________________________________\n","name":"stdout"}]},{"metadata":{},"cell_type":"markdown","source":"### How to Use the Conv2DTranspose Layer"},{"metadata":{"trusted":true},"cell_type":"code","source":"...\n# define input data\nX = np.asarray([[1, 2],\n\t\t\t [3, 4]])\n# show input data for context\nprint(X)","execution_count":30,"outputs":[{"output_type":"stream","text":"[[1 2]\n [3 4]]\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"...\n# reshape input data into one sample a sample with a channel\nX = X.reshape((1, 2, 2, 1))","execution_count":31,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"...\n# define model\nmodel = Sequential()\nmodel.add(Conv2DTranspose(1, (1,1), strides=(2,2), input_shape=(2, 2, 1)))\n# summarize the model\nmodel.summary()","execution_count":32,"outputs":[{"output_type":"stream","text":"Model: \"sequential_7\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\nconv2d_transpose (Conv2DTran (None, 4, 4, 1)           2         \n=================================================================\nTotal params: 2\nTrainable params: 2\nNon-trainable params: 0\n_________________________________________________________________\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"...\n# define weights that they do nothing\nweights = [np.asarray([[[[1]]]]), np.asarray([0])]\n# store the weights in the model\nmodel.set_weights(weights)","execution_count":34,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"...\n# make a prediction with the model\nyhat = model.predict(X)","execution_count":35,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"...\n# reshape output to remove channel to make printing easier\nyhat = yhat.reshape((4, 4))\n# summarize output\nprint(yhat)","execution_count":36,"outputs":[{"output_type":"stream","text":"[[1. 0. 2. 0.]\n [0. 0. 0. 0.]\n [3. 0. 4. 0.]\n [0. 0. 0. 0.]]\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"...\n# example of using padding to ensure that the output is only doubled\nmodel.add(Conv2DTranspose(1, (3,3), strides=(2,2), padding='same', input_shape=(2, 2, 1)))","execution_count":37,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Simple Generator Model With the Conv2DTranspose Layer"},{"metadata":{"trusted":true},"cell_type":"code","source":"...\n# define model\nmodel = Sequential()\n# define input shape, output enough activations for for 128 5x5 image\nmodel.add(Dense(128 * 5 * 5, input_dim=100))\n# reshape vector of activations into 128 feature maps with 5x5\nmodel.add(Reshape((5, 5, 128)))","execution_count":38,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"...\n# double input from 128 5x5 to 1 10x10 feature map\nmodel.add(Conv2DTranspose(1, (3,3), strides=(2,2), padding='same'))","execution_count":39,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# summarize model\nmodel.summary()","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.7.9","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":4}